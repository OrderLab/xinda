LOCAL_DIR_datanode=/data/ruiming/tmp1/cfs_mount/hadoop/datanode
CONTAINER_DIR_datanode=/hadoop/dfs/data

LOCAL_DIR_namenode=/data/ruiming/tmp1/cfs_mount/hadoop/namenode
CONTAINER_DIR_namenode=/hadoop/dfs/name

LOCAL_DIR_historyserver=/data/ruiming/tmp1/cfs_mount/hadoop/historyserver
CONTAINER_DIR_historyserver=/hadoop/yarn/timeline

LOCAL_DIR_nodemanager=/data/ruiming/tmp1/cfs_mount/hadoop/nodemanager
CONTAINER_DIR_nodemanager=/opt/hadoop-3.2.1/logs

# LOCAL_DIR_resourcemanager=
# CONTAINER_DIR_resourcemanager=

# NodeManager
## At first, I noticed something like 
## `<property><name>yarn.nodemanager.remote-app-log-dir</name><value>/app-logs</value></property>` 
## in `/opt/hadoop-3.2.1/etc/hadoop/yarn-site.xml`
# Then, I started a simple mrbench yarn application. 
# During the job, a new file named `application_123456789_0001` appeared in `/opt/hadoop-3.2.1/logs/userlogs`
# After the job finished, that file disappeared.
## It seems that HDFS will aggregate logs: 
## once an app finishes, the NodeMagnager will collect the log files, aggregates them, and then uploads the logs to HDFS.
# To prove it, type `hdfs dfs -cat /app-logs/root/logs-tfile/` and we will find the logs.
## So, for NodeManager, we should use mount `/opt/hadoop-3.2.1/logs`

# ResourceManager
## It primarily relies on network communication and doesn't use local disk space for storing application data or logs. 
## Its main responsibilities are resource allocation, scheduling, monitoring, and coordination of YARN applications.
# So, for ResourceManager, we just inject network faults
